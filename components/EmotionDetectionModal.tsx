import React, { useState, useRef, useEffect } from 'react';
import { X, Camera, Video, Smile, Meh, Frown, AlertCircle, CheckCircle, Loader2, Eye, Mic } from 'lucide-react';
import { Language } from '../types';

interface EmotionDetectionModalProps {
  isOpen: boolean;
  onClose: () => void;
  lang: Language;
  onEmotionDetected: (emotion: EmotionResult) => void;
}

interface EmotionResult {
  emotion: 'positive' | 'neutral' | 'negative';
  confidence: number;
  details: {
    facial: number;
    voice: number;
    context: number;
  };
  analysis: string;
}

export const EmotionDetectionModal: React.FC<EmotionDetectionModalProps> = ({ 
  isOpen, 
  onClose, 
  lang,
  onEmotionDetected 
}) => {
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [cameraActive, setCameraActive] = useState(false);
  const [emotionResult, setEmotionResult] = useState<EmotionResult | null>(null);
  const [analysisProgress, setAnalysisProgress] = useState(0);
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const streamRef = useRef<MediaStream | null>(null);

  const t = {
    title: { ko: 'ğŸ­ ê³ ê¸‰ ê°ì • ë¶„ì„', en: 'ğŸ­ Advanced Emotion Analysis' },
    subtitle: { ko: 'AI ê¸°ë°˜ ì–¼êµ´ í‘œì • ë° ìŒì„± ê°ì • ì¸ì‹', en: 'AI-based Facial Expression & Voice Emotion Recognition' },
    startCamera: { ko: 'ì¹´ë©”ë¼ ì‹œì‘', en: 'Start Camera' },
    stopCamera: { ko: 'ì¹´ë©”ë¼ ì¤‘ì§€', en: 'Stop Camera' },
    startAnalysis: { ko: 'ê°ì • ë¶„ì„ ì‹œì‘', en: 'Start Analysis' },
    analyzing: { ko: 'ë¶„ì„ ì¤‘...', en: 'Analyzing...' },
    facialAnalysis: { ko: 'ì–¼êµ´ í‘œì • ë¶„ì„', en: 'Facial Expression' },
    voiceAnalysis: { ko: 'ìŒì„± í†¤ ë¶„ì„', en: 'Voice Tone' },
    contextAnalysis: { ko: 'ë§¥ë½ ë¶„ì„', en: 'Context Analysis' },
    result: { ko: 'ë¶„ì„ ê²°ê³¼', en: 'Analysis Result' },
    confidence: { ko: 'ì‹ ë¢°ë„', en: 'Confidence' },
    positive: { ko: 'ê¸ì •ì ', en: 'Positive' },
    neutral: { ko: 'ì¤‘ë¦½', en: 'Neutral' },
    negative: { ko: 'ë¶€ì •ì ', en: 'Negative' },
    apply: { ko: 'ì ìš©í•˜ê¸°', en: 'Apply' },
    close: { ko: 'ë‹«ê¸°', en: 'Close' },
    cameraPermission: { ko: 'ì¹´ë©”ë¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤', en: 'Camera permission required' },
    instructions: { ko: 'ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í‘œì •ì„ ì§€ì–´ì£¼ì„¸ìš”', en: 'Start camera and show natural expression' }
  };

  useEffect(() => {
    if (!isOpen) {
      stopCamera();
    }
  }, [isOpen]);

  // ì¹´ë©”ë¼ ì‹œì‘
  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { 
          width: 640, 
          height: 480,
          facingMode: 'user'
        },
        audio: false
      });
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        streamRef.current = stream;
        setCameraActive(true);
      }
    } catch (error) {
      console.error('Camera access error:', error);
      alert(t.cameraPermission[lang]);
    }
  };

  // ì¹´ë©”ë¼ ì¤‘ì§€
  const stopCamera = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }
    setCameraActive(false);
  };

  // ê°ì • ë¶„ì„ ì‹œì‘
  const startAnalysis = async () => {
    if (!cameraActive || !videoRef.current || !canvasRef.current) {
      alert(lang === 'ko' ? 'ë¨¼ì € ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”' : 'Please start camera first');
      return;
    }

    setIsAnalyzing(true);
    setAnalysisProgress(0);
    setEmotionResult(null);

    // ë¹„ë””ì˜¤ì—ì„œ ì´ë¯¸ì§€ ìº¡ì²˜
    const canvas = canvasRef.current;
    const video = videoRef.current;
    const ctx = canvas.getContext('2d');
    
    if (ctx) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0);
    }

    // ì‹œë®¬ë ˆì´ì…˜: ë‹¨ê³„ë³„ ë¶„ì„
    // 1ë‹¨ê³„: ì–¼êµ´ í‘œì • ë¶„ì„ (0-33%)
    await simulateProgress(0, 33, 1000);
    const facialScore = analyzeFacialExpression();

    // 2ë‹¨ê³„: ìŒì„± í†¤ ë¶„ì„ (33-66%)
    await simulateProgress(33, 66, 1000);
    const voiceScore = analyzeVoiceTone();

    // 3ë‹¨ê³„: ë§¥ë½ ë¶„ì„ (66-100%)
    await simulateProgress(66, 100, 1000);
    const contextScore = analyzeContext();

    // ì¢…í•© ë¶„ì„
    const result = calculateEmotionResult(facialScore, voiceScore, contextScore);
    setEmotionResult(result);
    setIsAnalyzing(false);
  };

  // ì§„í–‰ë¥  ì‹œë®¬ë ˆì´ì…˜
  const simulateProgress = (start: number, end: number, duration: number): Promise<void> => {
    return new Promise(resolve => {
      const steps = 20;
      const stepDuration = duration / steps;
      const stepSize = (end - start) / steps;
      let current = start;

      const interval = setInterval(() => {
        current += stepSize;
        setAnalysisProgress(Math.min(current, end));
        
        if (current >= end) {
          clearInterval(interval);
          resolve();
        }
      }, stepDuration);
    });
  };

  // ì–¼êµ´ í‘œì • ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)
  const analyzeFacialExpression = (): number => {
    // ì‹¤ì œë¡œëŠ” TensorFlow.jsì˜ face-api.js ë˜ëŠ” MediaPipeë¥¼ ì‚¬ìš©
    // ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ëœë¤ ê°’ ìƒì„±
    const canvas = canvasRef.current;
    if (!canvas) return 0.5;

    const ctx = canvas.getContext('2d');
    if (!ctx) return 0.5;

    // ì´ë¯¸ì§€ ë°ì´í„° ë¶„ì„ (ë°ê¸° ê¸°ë°˜ ê°„ë‹¨í•œ ë¶„ì„)
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const data = imageData.data;
    
    let brightness = 0;
    for (let i = 0; i < data.length; i += 4) {
      brightness += (data[i] + data[i + 1] + data[i + 2]) / 3;
    }
    brightness /= (data.length / 4);

    // ë°ê¸°ë¥¼ ê°ì • ì ìˆ˜ë¡œ ë³€í™˜ (0-1)
    // ë°ì€ í‘œì • = ê¸ì •ì , ì–´ë‘ìš´ í‘œì • = ë¶€ì •ì 
    return Math.min(Math.max((brightness - 100) / 100, 0), 1);
  };

  // ìŒì„± í†¤ ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)
  const analyzeVoiceTone = (): number => {
    // ì‹¤ì œë¡œëŠ” Web Audio APIë¡œ ìŒì„± ì£¼íŒŒìˆ˜ ë¶„ì„
    // ë†’ì€ ì£¼íŒŒìˆ˜ = ê¸ì •ì , ë‚®ì€ ì£¼íŒŒìˆ˜ = ë¶€ì •ì 
    return 0.5 + (Math.random() - 0.5) * 0.4;
  };

  // ë§¥ë½ ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)
  const analyzeContext = (): number => {
    // ì‹¤ì œë¡œëŠ” ëŒ€í™” ë‚´ìš©, ì‹œê°„ëŒ€, ì´ì „ ê°ì • ìƒíƒœ ë“±ì„ ë¶„ì„
    const hour = new Date().getHours();
    // ì•„ì¹¨/ì €ë… = ê¸ì •ì , ëŠ¦ì€ ë°¤ = ë¶€ì •ì 
    if (hour >= 6 && hour <= 9) return 0.7; // ì•„ì¹¨
    if (hour >= 18 && hour <= 21) return 0.6; // ì €ë…
    if (hour >= 22 || hour <= 5) return 0.3; // ëŠ¦ì€ ë°¤
    return 0.5; // ë‚®
  };

  // ì¢…í•© ê°ì • ê²°ê³¼ ê³„ì‚°
  const calculateEmotionResult = (
    facial: number, 
    voice: number, 
    context: number
  ): EmotionResult => {
    // ê°€ì¤‘ í‰ê·  (ì–¼êµ´ 50%, ìŒì„± 30%, ë§¥ë½ 20%)
    const totalScore = facial * 0.5 + voice * 0.3 + context * 0.2;
    
    let emotion: 'positive' | 'neutral' | 'negative';
    let analysis: string;

    if (totalScore > 0.6) {
      emotion = 'positive';
      analysis = lang === 'ko'
        ? `ë¶„ì„ ê²°ê³¼, í˜„ì¬ ê¸ì •ì ì¸ ê°ì • ìƒíƒœì…ë‹ˆë‹¤.\n\nì–¼êµ´ í‘œì •ì—ì„œ ë¯¸ì†Œì™€ ë°ì€ í‘œì •ì´ ê°ì§€ë˜ì—ˆìœ¼ë©°, ìŒì„± í†¤ë„ í™œê¸°ì°¨ê³  ê¸ì •ì ì…ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ì»¨ë””ì…˜ìœ¼ë¡œ ë³´ì´ë©°, ì—…ë¬´ë‚˜ ëŒ€í™”ì— ì ê·¹ì ìœ¼ë¡œ ì„í•  ìˆ˜ ìˆëŠ” ìƒíƒœì…ë‹ˆë‹¤.\n\nì¶”ì²œ: ì´ ê¸ì •ì ì¸ ì—ë„ˆì§€ë¥¼ í™œìš©í•˜ì—¬ ì¤‘ìš”í•œ ì˜ì‚¬ê²°ì •ì´ë‚˜ ì°½ì˜ì ì¸ ì‘ì—…ì„ ì§„í–‰í•˜ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤.`
        : `Analysis shows you are in a positive emotional state.\n\nYour facial expression shows smiles and brightness, and your voice tone is energetic and positive. Overall, you appear to be in good condition and ready to actively engage in work or conversation.\n\nRecommendation: Leverage this positive energy for important decisions or creative work.`;
    } else if (totalScore < 0.4) {
      emotion = 'negative';
      analysis = lang === 'ko'
        ? `ë¶„ì„ ê²°ê³¼, í˜„ì¬ ë‹¤ì†Œ ë¶€ì •ì ì´ê±°ë‚˜ í”¼ê³¤í•œ ê°ì • ìƒíƒœì…ë‹ˆë‹¤.\n\nì–¼êµ´ í‘œì •ì—ì„œ ê¸´ì¥ì´ë‚˜ í”¼ë¡œê°€ ê°ì§€ë˜ì—ˆìœ¼ë©°, ìŒì„± í†¤ë„ ë‚®ê³  ì—ë„ˆì§€ê°€ ë¶€ì¡±í•´ ë³´ì…ë‹ˆë‹¤. ìŠ¤íŠ¸ë ˆìŠ¤ë‚˜ í”¼ë¡œê°€ ëˆ„ì ëœ ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì¶”ì²œ: ì ì‹œ íœ´ì‹ì„ ì·¨í•˜ê±°ë‚˜ ê°€ë²¼ìš´ ìŠ¤íŠ¸ë ˆì¹­ì„ í•˜ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ê²°ì •ì€ ì»¨ë””ì…˜ì´ íšŒë³µëœ í›„ì— í•˜ì‹œëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.`
        : `Analysis shows you are in a somewhat negative or tired emotional state.\n\nYour facial expression shows tension or fatigue, and your voice tone is low with less energy. You may be experiencing accumulated stress or fatigue.\n\nRecommendation: Take a short break or do light stretching. Consider postponing important decisions until your condition improves.`;
    } else {
      emotion = 'neutral';
      analysis = lang === 'ko'
        ? `ë¶„ì„ ê²°ê³¼, í˜„ì¬ ì¤‘ë¦½ì ì´ê³  ì•ˆì •ì ì¸ ê°ì • ìƒíƒœì…ë‹ˆë‹¤.\n\nì–¼êµ´ í‘œì •ê³¼ ìŒì„± í†¤ì´ í‰ì˜¨í•˜ê³  ê· í˜• ì¡í˜€ ìˆìŠµë‹ˆë‹¤. íŠ¹ë³„íˆ ê¸ì •ì ì´ê±°ë‚˜ ë¶€ì •ì ì´ì§€ ì•Šì€ ì°¨ë¶„í•œ ìƒíƒœë¡œ, ì¼ìƒì ì¸ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ê¸°ì— ì í•©í•©ë‹ˆë‹¤.\n\nì¶”ì²œ: í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ë©´ì„œ ê³„íšëœ ì—…ë¬´ë¥¼ ì°¨ê·¼ì°¨ê·¼ ì§„í–‰í•˜ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤. í•„ìš”ì‹œ ê¸ì •ì ì¸ ìê·¹ì„ í†µí•´ ì—ë„ˆì§€ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`
        : `Analysis shows you are in a neutral and stable emotional state.\n\nYour facial expression and voice tone are calm and balanced. You are in a composed state, neither particularly positive nor negative, suitable for routine work.\n\nRecommendation: Maintain your current state and proceed with planned tasks steadily. You can boost energy with positive stimuli if needed.`;
    }

    return {
      emotion,
      confidence: Math.min(Math.max(totalScore, 0.3), 0.95),
      details: {
        facial: facial,
        voice: voice,
        context: context
      },
      analysis
    };
  };

  // ê²°ê³¼ ì ìš©
  const applyResult = () => {
    if (emotionResult) {
      onEmotionDetected(emotionResult);
      onClose();
    }
  };

  if (!isOpen) return null;

  return (
    <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/50 backdrop-blur-sm animate-fade-in">
      <div className="bg-white dark:bg-slate-800 rounded-2xl shadow-2xl max-w-4xl w-full mx-4 max-h-[90vh] overflow-y-auto">
        {/* í—¤ë” */}
        <div className="bg-gradient-to-r from-purple-600 to-indigo-600 p-6 text-white rounded-t-2xl">
          <div className="flex items-start justify-between">
            <div>
              <h2 className="text-2xl font-bold mb-2">{t.title[lang]}</h2>
              <p className="text-sm opacity-90">{t.subtitle[lang]}</p>
            </div>
            <button
              onClick={onClose}
              className="p-2 hover:bg-white/20 rounded-lg transition"
            >
              <X className="w-6 h-6" />
            </button>
          </div>
        </div>

        {/* ë³¸ë¬¸ */}
        <div className="p-6 space-y-6">
          {/* ì¹´ë©”ë¼ ì˜ì—­ */}
          <div className="bg-slate-100 dark:bg-slate-900 rounded-xl overflow-hidden">
            <div className="relative aspect-video">
              <video
                ref={videoRef}
                autoPlay
                playsInline
                muted
                className="w-full h-full object-cover"
              />
              <canvas
                ref={canvasRef}
                className="hidden"
              />
              
              {!cameraActive && (
                <div className="absolute inset-0 flex items-center justify-center bg-slate-200 dark:bg-slate-800">
                  <div className="text-center">
                    <Camera className="w-16 h-16 mx-auto mb-4 text-slate-400" />
                    <p className="text-slate-600 dark:text-slate-400">
                      {t.instructions[lang]}
                    </p>
                  </div>
                </div>
              )}

              {/* ë¶„ì„ ì¤‘ ì˜¤ë²„ë ˆì´ */}
              {isAnalyzing && (
                <div className="absolute inset-0 bg-black/70 flex items-center justify-center">
                  <div className="text-center text-white">
                    <Loader2 className="w-12 h-12 mx-auto mb-4 animate-spin" />
                    <p className="text-lg font-medium mb-2">{t.analyzing[lang]}</p>
                    <div className="w-64 h-2 bg-white/20 rounded-full overflow-hidden">
                      <div 
                        className="h-full bg-gradient-to-r from-purple-500 to-indigo-500 transition-all duration-300"
                        style={{ width: `${analysisProgress}%` }}
                      />
                    </div>
                    <p className="text-sm mt-2 opacity-75">{Math.round(analysisProgress)}%</p>
                  </div>
                </div>
              )}
            </div>
          </div>

          {/* ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
          <div className="flex items-center justify-center gap-4">
            {!cameraActive ? (
              <button
                onClick={startCamera}
                className="flex items-center gap-2 px-6 py-3 bg-blue-600 hover:bg-blue-700 text-white rounded-lg font-medium transition"
              >
                <Video className="w-5 h-5" />
                {t.startCamera[lang]}
              </button>
            ) : (
              <>
                <button
                  onClick={stopCamera}
                  className="flex items-center gap-2 px-6 py-3 bg-red-600 hover:bg-red-700 text-white rounded-lg font-medium transition"
                >
                  <Video className="w-5 h-5" />
                  {t.stopCamera[lang]}
                </button>
                <button
                  onClick={startAnalysis}
                  disabled={isAnalyzing}
                  className="flex items-center gap-2 px-6 py-3 bg-purple-600 hover:bg-purple-700 disabled:bg-slate-400 text-white rounded-lg font-medium transition"
                >
                  <Eye className="w-5 h-5" />
                  {isAnalyzing ? t.analyzing[lang] : t.startAnalysis[lang]}
                </button>
              </>
            )}
          </div>

          {/* ë¶„ì„ ê²°ê³¼ */}
          {emotionResult && (
            <div className="space-y-4 animate-fade-in-up">
              {/* ì¢…í•© ê²°ê³¼ */}
              <div className={`p-6 rounded-xl border-2 ${
                emotionResult.emotion === 'positive' 
                  ? 'bg-green-50 dark:bg-green-900/20 border-green-300 dark:border-green-700'
                  : emotionResult.emotion === 'negative'
                  ? 'bg-red-50 dark:bg-red-900/20 border-red-300 dark:border-red-700'
                  : 'bg-slate-50 dark:bg-slate-900/50 border-slate-300 dark:border-slate-700'
              }`}>
                <div className="flex items-center justify-between mb-4">
                  <div className="flex items-center gap-3">
                    {emotionResult.emotion === 'positive' ? (
                      <Smile className="w-8 h-8 text-green-600" />
                    ) : emotionResult.emotion === 'negative' ? (
                      <Frown className="w-8 h-8 text-red-600" />
                    ) : (
                      <Meh className="w-8 h-8 text-slate-600" />
                    )}
                    <div>
                      <h3 className="text-xl font-bold text-slate-900 dark:text-white">
                        {t.result[lang]}
                      </h3>
                      <p className="text-sm text-slate-600 dark:text-slate-400">
                        {t[emotionResult.emotion][lang]}
                      </p>
                    </div>
                  </div>
                  <div className="text-right">
                    <div className="text-3xl font-bold text-slate-900 dark:text-white">
                      {(emotionResult.confidence * 100).toFixed(0)}%
                    </div>
                    <div className="text-xs text-slate-600 dark:text-slate-400">
                      {t.confidence[lang]}
                    </div>
                  </div>
                </div>

                {/* ìƒì„¸ ë¶„ì„ */}
                <div className="grid grid-cols-3 gap-4 mb-4">
                  <div className="text-center p-3 bg-white dark:bg-slate-800 rounded-lg">
                    <Eye className="w-5 h-5 mx-auto mb-2 text-blue-600" />
                    <div className="text-sm font-medium text-slate-700 dark:text-slate-300">
                      {t.facialAnalysis[lang]}
                    </div>
                    <div className="text-lg font-bold text-blue-600">
                      {(emotionResult.details.facial * 100).toFixed(0)}%
                    </div>
                  </div>
                  <div className="text-center p-3 bg-white dark:bg-slate-800 rounded-lg">
                    <Mic className="w-5 h-5 mx-auto mb-2 text-purple-600" />
                    <div className="text-sm font-medium text-slate-700 dark:text-slate-300">
                      {t.voiceAnalysis[lang]}
                    </div>
                    <div className="text-lg font-bold text-purple-600">
                      {(emotionResult.details.voice * 100).toFixed(0)}%
                    </div>
                  </div>
                  <div className="text-center p-3 bg-white dark:bg-slate-800 rounded-lg">
                    <CheckCircle className="w-5 h-5 mx-auto mb-2 text-green-600" />
                    <div className="text-sm font-medium text-slate-700 dark:text-slate-300">
                      {t.contextAnalysis[lang]}
                    </div>
                    <div className="text-lg font-bold text-green-600">
                      {(emotionResult.details.context * 100).toFixed(0)}%
                    </div>
                  </div>
                </div>

                {/* ë¶„ì„ ì„¤ëª… */}
                <div className="p-4 bg-white dark:bg-slate-800 rounded-lg">
                  <p className="text-sm text-slate-700 dark:text-slate-300 leading-relaxed whitespace-pre-line">
                    {emotionResult.analysis}
                  </p>
                </div>
              </div>

              {/* ì•¡ì…˜ ë²„íŠ¼ */}
              <div className="flex items-center justify-end gap-3">
                <button
                  onClick={onClose}
                  className="px-6 py-2 border border-slate-300 dark:border-slate-600 text-slate-700 dark:text-slate-300 rounded-lg hover:bg-slate-50 dark:hover:bg-slate-700 transition"
                >
                  {t.close[lang]}
                </button>
                <button
                  onClick={applyResult}
                  className="px-6 py-2 bg-purple-600 hover:bg-purple-700 text-white rounded-lg font-medium transition"
                >
                  {t.apply[lang]}
                </button>
              </div>
            </div>
          )}
        </div>
      </div>
    </div>
  );
};
